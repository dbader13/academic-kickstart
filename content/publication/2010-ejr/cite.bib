@inproceedings{2010-EJR+,
 abstract = {Social networks produce an enormous quantity of data. Facebook consists of over 400 million active users sharing over 5 billion pieces of information each month. Analyzing this vast quantity of unstructured data presents challenges for software and hardware. We present GraphCT, a Graph Characterization Toolkit for massive graphs representing social network data. On a 128-processor Cray XMT, GraphCT estimates the betweenness centrality of an artificially generated (R-MAT) 537 million vertex, 8.6 billion edge graph in 55 minutes and a real-world graph (Kwak, et al.) with 61.6 million vertices and 1.47 billion edges in 105 minutes. We use GraphCT to analyze public data from Twitter, a microblogging network. Twitter's message connections appear primarily tree-structured as a news dissemination system. Within the public data, however, are clusters of conversations. Using GraphCT, we can rank actors within these conversations and help analysts focus attention on a much smaller data subset.},
 address = {Los Alamitos, CA},
 author = {David Ediger and Karl Jiang and E. Jason Riedy and David A. Bader and Courtney Corley and Robert M. Farber and William N. Reynolds},
 bibsource = {dblp computer science bibliography, https://dblp.org},
 biburl = {https://dblp.org/rec/bib/conf/icpp/EdigerJRBCFR10},
 booktitle = {39th International Conference on Parallel Processing, ICPP 2010, San Diego, California, USA, 13-16 September 2010},
 doi = {10.1109/ICPP.2010.66},
 groups = {Edited},
 pages = {583--593},
 publisher = {IEEE Computer Society},
 timestamp = {Sun, 04 Jun 2017 01:00:00 +0200},
 title = {Massive Social Network Analysis: Mining {Twitter} for Social Good},
 url = {https://doi.org/10.1109/ICPP.2010.66},
 year = {2010}
}

